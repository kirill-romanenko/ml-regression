# ml-regression
## Постановка задачи

Предсказание цены дома в King County, USA.

Датасет - https://www.kaggle.com/datasets/harlfoxem/housesalesprediction/data
**Размер датасета**:
- **Строки:** 21613
- **Столбцы:** 21

**Названия столбцов:**

* **id**: уникальный идентификатор каждой проданной недвижимости  
* **date**: дата продажи дома  
* **price**: цена продажи дома  
* **bedrooms**: количество спален  
* **bathrooms**: количество ванных комнат (где .5 означает комнату с туалетом без душа)  
* **sqft_living**: общая площадь жилых помещений (в квадратных футах)  
* **sqft_lot**: площадь земельного участка (в квадратных футах)  
* **floors**: количество этажей  
* **waterfront**: признак, находится ли недвижимость у воды (1 = Да, 0 = Нет)  
* **view**: рейтинг вида из дома от 0 до 4 (чем больше, тем лучше вид)  
* **condition**: состояние жилья (оценка от 1 до 5, где 1 - плохое, 5 - отличное)  
* **grade**: оценка качества конструкции и дизайна (от 1 до 13)  
  * 1-3 - низкое качество,  
  * 7 - среднее,  
  * 11-13 - высокое качество)  
* **sqft_above**: площадь жилой зоны над уровнем земли (в квадратных футах)  
* **sqft_basement**: площадь подвала (в квадратных футах)  
* **yr_built**: год постройки дома  
* **yr_renovated**: год последней реконструкции дома (0, если не реконструировался)  
* **zipcode**: почтовый индекс района, где находится дом  
* **lat**: широта  
* **long**: долгота  
* **sqft_living15**: средняя площадь жилого пространства ближайших 15 соседей  
* **sqft_lot15**: средняя площадь земельных участков ближайших 15 соседей

## EDA

- Датасет не имеет пропусков и дубликатов.

- Отрицательных значений нет. Лишних значений в категориальных признаках нет.

- **Сильная группа признаков, связанных с размерами дома**:  
  *sqft_living*, *sqft_above*, *sqft_basement*, *grade*, *bathrooms* имеют очень высокие взаимные корреляции (0.7–0.92).  
  Это указывает на сильную избыточность - все они описывают один и тот же скрытый фактор: **размер и качество дома**.

- **Площадь участка (*sqft_lot*)** почти не связана с ценой (0.21) - размер участка не влияет значительно на стоимость,  
  но умеренно коррелирует с *floors* (0.36) и *sqft_lot15* (0.63).

- **Показатели близлежащих домов** (*sqft_living15* и *sqft_lot15*) связаны с соответствующими характеристиками этого дома  
  (*sqft_living* - 0.74, *sqft_lot* - 0.63), но слабее влияют на цену напрямую.

- **Географические координаты**:  
  - *zipcode*, *lat*, *long* имеют заметные взаимные связи (до 0.79), отражая пространственную структуру данных.  
  - Корреляция с *price* умеренная (0.18-0.34) - расположение влияет, но не решающе.

- **Качество конструкции (*grade*)** сильно коррелирует с *sqft_living* (0.75) и *bathrooms* (0.72).  

- **Нахождение у воды и вид**:  
  - *waterfront* (0.42) и *view* (0.46) заметно связаны с ценой.  
  - Эти признаки выражают **премиум‑расположение**, добавляющее стоимости независимо от других метрик.

- **Слабые связи:**  
  *date*, *floors*, *zipcode*, *condition* имеют слабую или незначимую корреляцию с основными признаками и *price*.  

- **Цена дома (*price*)** максимально коррелирует с:  
  *sqft_living* (0.90), *sqft_above* (0.79), *sqft_basement* (0.79), *bathrooms* (0.74), *grade* (0.66), *sqft_living15* (0.54).  
  **Чем больше площадь и выше качество строительства, тем выше цена**.

- Меньше всего продаж в субботу и воскресенье.

- **bedrooms:** можно сгруппировать как 0, 1-2, 3-5, 6+.  
- **bathrooms:** можно сгруппировать как 0, 0.5-1.75, 2-5, 6+.
- **floors:** можно сгруппировать как 1-1.5, 2-2.5, 3+.
- **sqft_living, sqft_lot, sqft_above, sqft_living15, sqft_lot15, price:** применить логарифмическое преобразование (правосторонняя асимметрия).  
- **sqft_basement:** много нулей, создать бинарный признак "наличие подвала".  
- **yr_renovated:** много нулей, создать бинарный признак "реконструирован / нет".
- Необходимо учитывать **дату продажи дома *date*** при разбиении на обучающую и тестовую выборки, а также использовать TimeSeriesSplit при кроссвалидации.

## Baseline

### Использованные модели
- Dummy Regressor
- Линейная регрессия (LinearRegression)
- Дерево решений (DecisionTreeRegressor)
- Случайный лес (RandomForestRegressor)
- LGBMRegressor
- CatBoostRegressor

### Важности признаков для моделей
Для расчета важности признаков использовалась библиотека SHAP
#### LinearRegression
На первых местах для линейной регрессии оказались признаки **grade** и **sqft_living** у которых наблюдались сильные корреляции с таргетом **Churn**. Также на третьем местре находится **lat**, значит модель уловила зависимость от местоположения дома.
<img width="790" height="589" alt="изображение" src="https://github.com/user-attachments/assets/0c6656b3-5904-41ff-ad29-0ac022d7c4c2" />

#### DecisionTreeRegressor
У дерева на первых местах тоже наблюдаются **grade**, **sqft_living** и **lat**, однако важность большинства остальных признаков равна нулю
<img width="790" height="589" alt="изображение" src="https://github.com/user-attachments/assets/9832f9de-a17a-4d87-a313-69142ac5c720" />

#### RandomForestRegressor
У случайного леса на первых местах тоже наблюдаются **lat**, **sqft_living** и **grade**. Также в топе появляются **long** и **sqft_living15**. Видимо модель нашла более сложныые закономерности
<img width="790" height="589" alt="изображение" src="https://github.com/user-attachments/assets/f9c2259f-07da-43d1-b5aa-e8ec30869203" />

#### LGBMRegressor
LGBMClassifier также в основном смотрит на **lat**, **grade**, **sqft_living**, **long** и **sqft_living15**. Важность остальных признаков уже не такая маленькая как у случайного леса
<img width="789" height="589" alt="изображение" src="https://github.com/user-attachments/assets/fb4b719b-c3b1-4ea4-ada4-de68e2d088dd" />

#### CatBoostRegressor
Catboost тоже отдает сильное предпочтение **lat**, **sqft_living**, **grade**, **long**, но разброс важности остальных признаков стал еще меньше чем у прошлых моделей
<img width="790" height="589" alt="изображение" src="https://github.com/user-attachments/assets/29755024-5492-409d-852f-ae1bcb154ad8" />

### Сравнение метрик
По метрикам хуже всех показал себя dummy_regressor. 

Достаточно хорошо показали себя модели Случайного леса, lgbm и catboost.

Самой лучшей моделью оказался Catboost (R2 - 0.9, MAPE - 0.12).
<img width="825" height="351" alt="изображение" src="https://github.com/user-attachments/assets/9037e325-ac0e-40fb-91eb-327aece04fde" />

## Improvements

Сначало каждое преобразование тестировалось отдельно и сравнивалось с бейслайном, затем выбирались только лучшие и комбинировались

### Применяемые преобразования
- Логарифмическое преобразование признаков sqft_living, sqft_lot, sqft_above, sqft_living15, sqft_lot15 (без/с удалением столбцов)
- Логарифмическое преобразование таргета price
- Создание нового признака has_basement (есть ли подвал)
- Биннинг bedrooms (без/с удалением столбца)

  разбиение на группы 0, 1-2, 3-5, 6+.
- Биннинг bathrooms (без/с удалением столбца)

  разбиение на группы 0, 0.5-1.75, 2-5, 6+.
- Биннинг floors (без/с удалением столбца)

  разбиение на группы 1-1.5, 2-2.5, 3+.
- Создание нового признака was_renovated (реконструировался ли дом)
- Применение StandardScaler (стандартизация)
- Применение MinMaxScaler (нормализация)
- Применение RobustScaler
- Применение CatBoostEncoder для категориальных переменных
- Обработка выбросов (Winsorize | IsolationForest)
- Создание нового признака sqft_per_room (средняя площадь на комнату)
- Создание нового признака ratio_living_lot (доля жилой площади относительно участка)
- Создание нового признака house_age (возраст дома на момент продажи)
- Создание нового признака sqft_diff (отклонение площади дома от окрестных домов)

### Лучшие преобразования
Сравнение происходило с изначальными метриками без преобразований

Изменения показаны в процентах
1. Логарифмическое преобразование таргета **price**

   Большое улучшение у линейной регрессии.

   У градиентных бустингов немного улучшился mape, r2 не изменился
   <img width="764" height="390" alt="изображение" src="https://github.com/user-attachments/assets/abbc0560-ad00-45c6-a81e-532f5c62c0fb" />

2. Удаление выбросов с помощью **IsolationForest**

   После удаления выбросов логично сильно увеличились MAE и RMSE. Для более стабильной работы моделей можно оставить это преобразование
   <img width="764" height="390" alt="изображение" src="https://github.com/user-attachments/assets/d6cd33a0-272b-495f-9200-7d1bc5d22e4a" />

### Комбинация лучших преобразований
Сравнение с изначальными метриками:
<img width="764" height="390" alt="изображение" src="https://github.com/user-attachments/assets/460626f2-fe8c-477f-8847-e8b5ead9423c" />

### Выбор окончательной модели
Лучше всего по метрикам показал себя catboost.

Он будет использован для дальнейшего подбора гиперпараметров.

Метрики моделей после применения комбинации лучших преобразований:
<img width="779" height="390" alt="изображение" src="https://github.com/user-attachments/assets/1c4f5536-0184-4ac1-a57a-672e349532cf" />

## Подбор гиперпараметров

### Метод подбора гиперпараметров
Для тюнинга гиперпараметров использовалась библиотека **Optuna** вместе с кроссвадидацией (TimeSeriesSplit).

- Оптимизируемые метрики: MAE и RMSE
- Количество шагов: 150
- Время подбора: ~ 2 ч. 35 мин.

### Интервалы перебора
``` python
bootstrap_type = trial.suggest_categorical(
        "bootstrap_type", ["Bayesian", "Bernoulli", "MVS"]
    )  # тип бутстрэпа (способ семплирования объектов при обучении)

params = {
    "iterations": trial.suggest_int(
        "iterations", 500, 3000
    ),  # количество деревьев (итераций бустинга); влияет на силу модели и риск переобучения
    "depth": trial.suggest_int(
        "depth", 4, 10
    ),  # глубина деревьев; больше — сложнее зависимости, выше риск переобучения
    "learning_rate": trial.suggest_float(
        "learning_rate", 0.005, 0.3, log=True
    ),  # шаг обучения; меньше — стабильнее и точнее, но требует больше деревьев
    "l2_leaf_reg": trial.suggest_float(
        "l2_leaf_reg", 1e-3, 30.0, log=True
    ),  # L2-регуляризация весов листьев; увеличивает устойчивость и снижает переобучение
    "min_data_in_leaf": trial.suggest_int(
        "min_data_in_leaf", 5, 200
    ),  # минимальное число объектов в листе; больше — более сглаженная модель
    "random_strength": trial.suggest_float(
        "random_strength", 0.0, 2.0
    ),  # уровень случайности при выборе сплитов; действует как регуляризация
    "rsm": trial.suggest_float(
        "rsm", 0.5, 1.0
    ),  # доля признаков для каждого дерева (feature sampling); снижает переобучение
    "bootstrap_type": bootstrap_type,  # метод семплирования объектов: Bayesian (взвешенный), Bernoulli (subsample), MVS (градиентный)
    "loss_function": trial.suggest_categorical(
        "loss_function", ["RMSE", "MAE"]
    ),  # функция потерь: RMSE — чувствителен к выбросам, MAE — устойчив к выбросам
    "od_type": "Iter",  # тип early stopping — остановка при отсутствии улучшения
    "od_wait": trial.suggest_int(
        "od_wait", 30, 200
    )  # сколько итераций ждать улучшения перед остановкой
}

# Зависимые параметры bootstrap
if bootstrap_type == "Bayesian":
    params["bagging_temperature"] = trial.suggest_float(
        "bagging_temperature", 0.0, 10.0
    )  # интенсивность байесовского бутстрэпа; больше — сильнее регуляризация

elif bootstrap_type == "Bernoulli":
    params["subsample"] = trial.suggest_float(
        "subsample", 0.5, 1.0
    )  # доля объектов для каждого дерева; уменьшает переобучение и ускоряет обучение

elif bootstrap_type == "MVS":
    params["subsample"] = trial.suggest_float(
        "subsample", 0.6, 1.0
    )  # доля объектов при градиентном семплинге; баланс скорости и точности
```
### График изменения RMSE и MAE по время подбора гиперпараметров
<img width="698" height="450" alt="newplot" src="https://github.com/user-attachments/assets/be7897ca-4d69-43d7-84bc-c1be4941d5eb" />

### Подобранные значения гиперпараметров
#### Лучшие значения гиперпараметров
- Гиперпараметры минимизирующие MAE:
  
  ```python
  {'bootstrap_type': 'Bernoulli',
   'iterations': 2390,
   'depth': 7,
   'learning_rate': 0.026545629176856086,
   'l2_leaf_reg': 0.10354243602548131,
   'min_data_in_leaf': 197,
   'random_strength': 1.5236018770721467,
   'rsm': 0.5998574249658826,
   'loss_function': 'RMSE',
   'od_wait': 195,
   'subsample': 0.7210723822028944}
  ```
- Гиперпараметры минимизирующие RMSE:
  
  ```python
  {'bootstrap_type': 'MVS',
  'iterations': 1669,
  'depth': 6,
  'learning_rate': 0.07635918053104514,
  'l2_leaf_reg': 5.142533035004691,
  'min_data_in_leaf': 158,
  'random_strength': 1.7962481199804916,
  'rsm': 0.6978172821020538,
  'loss_function': 'RMSE',
  'od_wait': 138,
  'subsample': 0.9371407071033508}
  ```
#### График важности гиперпараметров
Самый важный гиперпараметр - bootstrap_type
<img width="715" height="450" alt="newplot" src="https://github.com/user-attachments/assets/e4410ed6-4d1f-4757-9fcd-40cdc81b4960" />

### Сравнение модели до и после подбора гиперпараметров
#### Исходные метрики
<img width="747" height="390" alt="изображение" src="https://github.com/user-attachments/assets/386f980a-fea6-4284-b35b-3c3fbd543aa6" />

#### Метрики после подбора гиперпараметров минимизирующих MAE
<img width="747" height="390" alt="изображение" src="https://github.com/user-attachments/assets/5c126872-4719-411d-911b-618b2efd4c82" />

#### Метрики после подбора гиперпараметров минимизирующих RMSE
<img width="747" height="390" alt="изображение" src="https://github.com/user-attachments/assets/8e892dd5-0100-4dc8-b53a-db867aba5948" />

#### Сравнение и изначальными метриками
После подбора гиперпараметров минимизирующих MAE:
- MAE улучшился на 1.1%
- RMSE улучшился на 0.5%
- MAPE улучшился на 0.8%
- R2 практически не изменился

<img width="747" height="390" alt="изображение" src="https://github.com/user-attachments/assets/3669d0fb-1ef8-478a-8936-c3e35926b64b" />

После подбора гиперпараметров минимизирующих RMSE:
- MAE улучшился на 0.7%
- RMSE улучшился на 1.0%
- MAPE и R2 улучшились на 0.3%

<img width="747" height="390" alt="изображение" src="https://github.com/user-attachments/assets/62d30afd-4f48-404e-90a3-2e6c2c4a501c" />

#### Вывод
Если важна устойчивость к выбросам и крупным ошибкам, лучше оптимизировать RMSE.

Если важна средняя абсолютная точность прогноза, лучше оптимизировать MAE.
